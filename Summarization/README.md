Welcome!

In this project I fine-tune one of T5-efficient variants to do abstractive summarization of messenger like conversations. 

Model that I'm fine-tuning was introduced in this paper https://arxiv.org/abs/2109.10686. It's a study about scaling properties of transformers based models. 
I chose a model that's performance was outstanding compared to models of similar size.

I used Samsum dataset which is a collection of messenger like conversations and their rather short summaries written by linguists fluent in English.


